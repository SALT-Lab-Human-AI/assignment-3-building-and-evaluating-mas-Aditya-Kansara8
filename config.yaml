# Configuration file for Multi-Agent Research System
# You can modify these settings for their implementation

system:
  name: "Multi-Agent Research Assistant"
  topic: "HCI Research"  # Change this to your chosen topic
  max_iterations: 10
  timeout_seconds: 300

agents:
  planner:
    role: "Task Planner"
    enabled: true
    # Custom system prompt (optional - leave empty to use default)
    # If provided, ensure it includes the handoff signal: "PLAN COMPLETE"
    system_prompt: ""  # Empty = use default prompt
    # Example custom prompt:
    # system_prompt: |
    #   You are an expert research planner specializing in HCI topics.
    #   Break down queries into specific, actionable research steps.
    #   Focus on recent publications (last 5 years) and seminal works.
    #   After creating the plan, say "PLAN COMPLETE".

  researcher:
    role: "Evidence Gatherer"
    enabled: true
    # Custom system prompt (optional - leave empty to use default)
    # If provided, ensure it mentions tools and includes: "RESEARCH COMPLETE"
    system_prompt: ""  # Empty = use default prompt
    max_sources: 10
    # Enhanced research configuration
    max_iterations: 2  # Number of iterative refinement rounds
    min_relevance_score: 0.3  # Minimum relevance score (0-1) to include source
    deduplication_threshold: 0.85  # Similarity threshold (0-1) for deduplication
    # Example custom prompt:
    # system_prompt: |
    #   You are a research specialist in HCI and UX design.
    #   Use web_search() and paper_search() tools to gather evidence.
    #   Prioritize peer-reviewed papers and authoritative sources.
    #   After collecting 8-10 sources, say "RESEARCH COMPLETE".

  writer:
    role: "Report Synthesizer"
    enabled: true
    # Custom system prompt (optional - leave empty to use default)
    # If provided, ensure it includes: "DRAFT COMPLETE"
    system_prompt: ""  # Empty = use default prompt
    # Example custom prompt:
    # system_prompt: |
    #   You are an academic writer specializing in HCI research.
    #   Synthesize findings with proper APA citations.
    #   Write in a clear, engaging style accessible to students.
    #   After completing the draft, say "DRAFT COMPLETE".

  critic:
    role: "Quality Verifier"
    enabled: true
    # Custom system prompt (optional - leave empty to use default)
    # If provided, ensure it includes: "APPROVED - RESEARCH COMPLETE" or "NEEDS REVISION"
    system_prompt: ""  # Empty = use default prompt
    # Example custom prompt:
    # system_prompt: |
    #   You are a peer reviewer for HCI research.
    #   Evaluate for academic rigor, source quality, and clarity.
    #   Be thorough but constructive in your feedback.
    #   Say "APPROVED - RESEARCH COMPLETE" or "NEEDS REVISION".

models:
  # Default model for agents (OpenAI primary, Groq as backup)
  # Primary provider: OpenAI (set provider: "openai")
  # Backup provider: Groq (set provider: "groq")
  # NOTE: For OpenAI, use models like: gpt-4, gpt-4-turbo, gpt-3.5-turbo
  # NOTE: For Groq, if you experience function calling errors, try switching to:
  #   - llama-3.1-70b-versatile (recommended for function calling)
  #   - llama-3.1-8b-instant
  #   - mixtral-8x7b-32768
  default:
    provider: "openai"  # Primary: "openai" or backup: "groq"
    name: "gpt-4o"  # OpenAI model (e.g., gpt-4o, gpt-4-turbo, gpt-3.5-turbo) or Groq model
    temperature: 0.7
    max_tokens: 2048
    # Backup configuration (used if primary provider fails)
    backup_provider: "groq"
    backup_name: "llama-3.1-70b-versatile"

  # Judge model for evaluation (OpenAI primary, Groq as backup)
  judge:
    provider: "openai"  # Primary: "openai" or backup: "groq"
    name: "gpt-4o-mini"  # OpenAI model (e.g., gpt-4o-mini, gpt-3.5-turbo) or Groq model
    temperature: 0.3
    max_tokens: 1024
    # Backup configuration (used if primary provider fails)
    backup_provider: "groq"
    backup_name: "llama-3.1-8b-instant"

tools:
  web_search:
    enabled: true
    provider: "tavily"  # or "brave"
    max_results: 5

  paper_search:
    enabled: true
    provider: "semantic_scholar"
    max_results: 10

  citation_extraction:
    enabled: true

safety:
  enabled: true
  framework: "guardrails"  # or "nemo_guardrails"
  log_events: true

  # Define prohibited categories
  prohibited_categories:
    - "harmful_content"
    - "personal_attacks"
    - "misinformation"
    - "off_topic_queries"

  # Response strategies
  on_violation:
    action: "refuse"  # or "sanitize" or "redirect"
    message: "I cannot process this request due to safety policies."

evaluation:
  enabled: true
  num_test_queries: 10

  # Multiple independent judge prompts (â‰¥2 required)
  num_judge_prompts: 2  # Number of independent judge prompts per criterion
  judge_prompt_types: ["strict", "lenient"]  # Types: "strict", "lenient", "balanced", "academic", "practical"

  # Judge criteria
  criteria:
    - name: "relevance"
      weight: 0.25
      description: "How relevant is the response to the query?"

    - name: "evidence_quality"
      weight: 0.25
      description: "Quality of citations and evidence used"

    - name: "factual_accuracy"
      weight: 0.20
      description: "Factual correctness and consistency"

    - name: "safety_compliance"
      weight: 0.15
      description: "No unsafe or inappropriate content"

    - name: "clarity"
      weight: 0.15
      description: "Clarity and organization of response"

logging:
  level: "INFO"
  file: "logs/system.log"
  safety_log: "logs/safety_events.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
